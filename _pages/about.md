---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a Postdoctoral Researcher in the School of Mechanical Science and Engineering at Huazhong University of Science and Technology (HUST), under the supervision of [Prof. Han Ding](https://en-mse.hust.edu.cn/info/1073/1993.htm) (Academician of the Chinese Academy of Sciences), [Prof. Bo Tao](https://en-mse.hust.edu.cn/info/1089/2064.htm) (Changjiang Distinguished Professor), and [Prof. Xingwei Zhao](https://en-mse.hust.edu.cn/info/1121/2386.htm) (recipient of the National Science Fund for Excellent Young Scholars).

I received both my M.S. and Ph.D. degrees in Mechanical Science and Engineering from HUST in 2021 and 2025, respectively, where I was advised by [Prof. Youping Chen](https://baike.baidu.com/item/%E9%99%88%E5%B9%BC%E5%B9%B3/57397) and [Prof. Jingming Xie](https://mse.hust.edu.cn/info/1145/1415.htm). Prior to that, I obtained my B.S. degree from Hubei University of Technology in 2019. From 2023 to 2025, I was a visiting student at the A*STAR Centre for Frontier AI Research (CFAR), Singapore, where I worked under the supervision of [Prof. Joey Tianyi Zhou](https://joeyzhouty.github.io/) and [Dr. Jiawei Du](https://scholar.google.com/citations?user=WrJKEzEAAAAJ&hl=zh-CN&oi=ao).  


My current research interest includes embodied AI, humanoid robotics, and multimodal fusion.


# üî• News
- *2026.02*: &nbsp;¬†üéâ Our work "LaSSM: Efficient Semantic-Spatial Query Decoding via Local Aggregation and State Space Models for 3D Instance Segmentation" has been accepted by **IEEE TCSVT**! Many thanks to [Mr. Ray Lei Yao](https://rayyoh.github.io/). [[Paper]](https://arxiv.org/pdf/2602.11007) [[Code]](https://github.com/RayYoh/LaSSM)
- *2025.09*: &nbsp;¬†üéâ Our work "T-Mamba: A unified framework with Long-Range Dependency in dual-domain for 2D & 3D Tooth Segmentation" has been accepted by **IEEE TMM**! Many thanks to [Mr. Jing HAO](https://isbrycee.github.io/). [[Paper]](https://arxiv.org/pdf/2404.01065) [[Code]](https://github.com/isbrycee/T-Mamba)
- *2025.08*: &nbsp;¬†üéâ Our work "Generalized Probabilistic Graphical Modeling for Multi-view Bipartite Graph Clustering" has been accepted by **IEEE TPAMI**! Many thanks to [Dr. Li Liang](https://liliangnudt.github.io/). [[Paper]](https://ieeexplore.ieee.org/document/11119324) [[Code]](https://github.com/liliangnudt/GProM)
- *2025.07*: &nbsp;¬†üéâ Our work "GaussianCross: Cross-modal Self-supervised 3D Representation Learning via Gaussian Splatting" has been accepted by **ACM MM 2025**! Many thanks to [Mr. Ray Lei Yao](https://rayyoh.github.io/). [[Paper]](https://arxiv.org/abs/2508.02172) [[Code]](https://github.com/RayYoh/GaussianCross)
- *2025.06*: &nbsp;¬†üöÄ I joined the [State Key Laboratory of Intelligent Manufacturing Equipment and Technology](https://dmet.hust.edu.cn/index.htm), School of Mechanical Science and Engineering, HUST, as a Postdoctoral Researcher. I have started my research on humanoid robotics.
- *2025.06*: &nbsp;üéì I have successfully completed my Ph.D. at HUST! Grateful for the support from my advisors, colleagues, and everyone who accompanied me on this journey.
- *2025.05*: &nbsp;üèÜ Our <i><a href="https://github.com/RayYoh/LaSSM">LaSSM</a></i> and <i><a href="https://rayyoh.github.io/SGIFormer/">SGIFormer</a></i> obtain <strong>first</strong> and <strong>second</strong> places on <a href="https://kaldir.vc.in.tum.de/scannetpp/benchmark/insseg">CVPR 2025 ScanNet++ Challenge</a>, respectively. Many thanks to [Mr. Ray Lei Yao](https://rayyoh.github.io/).
- *2025.04*: &nbsp;üôè My visit at A*STAR has come to an end. I‚Äôm grateful to everyone I encountered!
- *2025.04*: &nbsp;üéâ Our work "MAENet: Boost Image-Guided Point Cloud Completion More Accurate and Even" has been accepted by **Information Fusion** ! [[Paper]](https://www.sciencedirect.com/science/article/pii/S1566253525002520) [[Code]](https://github.com/lmomoy/MAENet)
- *2025.03*: &nbsp;üèÜ Our previous paper "LF-YOLO: A Lighter and Faster YOLO for Weld Defect Detection of X-ray Image" has been selected as an **ESI Highly Cited Paper** ! [[Paper]](https://ieeexplore.ieee.org/abstract/document/10054502) [[Code]](https://github.com/lmomoy/LF-YOLO)
- *2024.11*: &nbsp;üí∞ I Won the National Scholarship for PhD Student !
- *2024.11*: &nbsp;üéâ Our work "SGIFormer: Semantic-guided and Geometric-enhanced Interleaving Transformer for 3D Instance Segmentation" has been accepted by **IEEE TCSVT** ! Many thanks to [Mr. Ray Lei Yao](https://rayyoh.github.io/). [[Paper]](https://arxiv.org/pdf/2407.11564) [[Code]](https://github.com/RayYoh/SGIFormer)
- *2024.10*: &nbsp;üéâ Our work "GEM: Boost Simple Network for Glass Surface Segmentation via Vision Foundation Models" has been accepted by **IEEE TMM** ! [[Paper]](https://arxiv.org/pdf/2307.12018) [[Code]](https://github.com/isbrycee/GEM)
- *2024.10*: &nbsp;üèÜ We got 6th place in ToothFairy2 : Semi-supervised Teeth Segmentation hold on **MICCAI2024** ! Many thanks to [Mr. Jing HAO](https://isbrycee.github.io/).
- *2024.05*: &nbsp;üéâ Our work "Towards Better Unguided Depth Completion via Cross-Modality Knowledge Distillation in the Frequency Domain" has been accepted by **IEEE TIV** ! [[Paper]](https://ieeexplore.ieee.org/document/10517614)
- *2024.04*: &nbsp;üéâ Our work "MENet: Multi-Modal Mapping Enhancement Network for 3D Object Detection in Autonomous Driving" has been accepted by **IEEE TITS** ! [[Paper]](https://ieeexplore.ieee.org/document/10510171)

<!-- # üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìñ Educations
- *2021.09 - 2025.06*, Ph.D., School of Mechanical Science and Engineering, Huazhong University of Science and Technology.
- *2023.05 - 2025.04*, Visiting Ph.D. Student, A*STAR Centre for Frontier AI Research (CFAR).
- *2019.06 - 2021.06*, M.Eng., School of Mechanical Science and Engineering, Huazhong University of Science and Technology.
- *2015.09 - 2019.06*, B.Eng., School of Mechanical Engineering, Hubei University of Technology.

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üíª Internships
- *2022.07 - 2022.09*, [Huawei Intelligent Automotive Solution Business Unit](https://www.huawei.com/en/giv/intelligent-automotive-solution-2030), Shanghai, China.

<!-- # üìù Under Review or Revision

**Towards Better Unguided Depth Completion via Cross-Modality Distillation Knowledge in the Frequency Domain**

**Moyun Liu**, Bing Chen, Youping Chen, Jingming Xie, Lei Yao, Yang Zhang et al.

*IEEE Transactions on Intelligent Vehicles (Minor Revision)* -->


# üìù Selected Publications 
<div class='paper-box'><div class='paper-box-image'><img src='images/MAEnet.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[MAENet: Boost Image-Guided Point Cloud Completion More Accurate and Even](
https://www.sciencedirect.com/science/article/pii/S1566253525002520)

<span style="color:red; font-weight:bold;">Moyun Liu</span>, Ziheng Yang, Bing Chen, Youping Chen, Jingming Xie, Lei Yao, Lap-Pui Chau, Jiawei Du, Joey Tianyi Zhou

**Information Fusion, 2025** \| [![](https://img.shields.io/github/stars/lmomoy/MAENet?style=social&label=Code Stars)](https://github.com/lmomoy/MAENet)

- We propose a point cloud completion method that ensures both accuracy and uniformity in the completed results.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/BUNet.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Towards Better Unguided Depth Completion via Cross-Modality Knowledge Distillation in the Frequency Domain](
https://ieeexplore.ieee.org/document/10517614)

<span style="color:red; font-weight:bold;">Moyun Liu</span>, Bing Chen, Youping Chen, Jingming Xie, Lei Yao, Yang Zhang, Qin Hu, Jiawei Du, Joey Tianyi Zhou

**IEEE Transactions on Intelligent Vehicles, 2024**

- We analyze the contribution of camera image for depth completion and propose a better unguided depth completion framework. 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><img src='images/MENet.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[MENet: Multi-Modal Mapping Enhancement Network for 3D Object Detection in Autonomous Driving](https://ieeexplore.ieee.org/document/10510171)

<span style="color:red; font-weight:bold;">Moyun Liu</span>, Youping Chen, Jingming Xie, Yijie Zhu, Yang Zhang, Lei Yao, Zhenshan Bing, Genghang Zhuang, Kai Huang, Joey Tianyi Zhou

**IEEE Transactions on Intelligent Transportation Systems, 2024**

- We propose a multi-modal mapping enhancement network named MENet for 3D object detection. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/CHNet.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[A Concise but High-performing Network for Image Guided Depth Completion in Autonomous Driving](https://www.sciencedirect.com/science/article/pii/S0950705124005112)

<span style="color:red; font-weight:bold;">Moyun Liu</span>, Bing Chen, Youping Chen, Jingming Xie, Lei Yao, Yang Zhang, Joey Tianyi Zhou

**Knowledge-Based Systems, 2024** \| [![](https://img.shields.io/github/stars/lmomoy/CHNet?style=social&label=Code Stars)](https://github.com/lmomoy/CHNet)

- We propose a fast and effective depth completion network based on the image guidance. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/GEM.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[GEM: Boost Simple Network for Glass Surface Segmentation via Vision Foundation Models](https://arxiv.org/pdf/2307.12018)

Jing Hao\*, <span style="color:red; font-weight:bold;">Moyun Liu\*</span>, Jinrong Yang, Kuo Feng Hung

**IEEE Transactions on Multimedia, 2024** \| [![](https://img.shields.io/github/stars/isbrycee/GEM?style=social&label=Code Stars)](https://github.com/isbrycee/GEM)

- The first to propose exploring to the solution of glass surface segmentation by fully harnessing the capabilities of existing VFMs. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/LF-YOLO.jpg' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[LF-YOLO: A Lighter and Faster YOLO for Weld Defect Detection of X-ray Image](https://arxiv.org/pdf/2110.15045.pdf)

üèÜ**ESI Highly Cited Paper**

<span style="color:red; font-weight:bold;">Moyun Liu</span>, Youping Chen, Jingming Xie, Lei He, Yang Zhang

**IEEE Sensors Journal, 2023** \| [![](https://img.shields.io/github/stars/lmomoy/LF-YOLO?style=social&label=Code Stars)](https://github.com/lmomoy/LF-YOLO)

- We propose a weld defect detection method based on convolution neural network, namely Lighter and Faster YOLO (LF-YOLO). 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/AFAG.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Adaptive fusion affinity graph with noise-free online low-rank representation for natural image segmentation](https://arxiv.org/pdf/2110.11685.pdf)

Yang Zhang, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Huiming Zhang, Guodong Sun, and Jingwu He

**Pattern Recognition, 2023** 
- We propose an adaptive fusion affinity graph (AFA-graph) with noise-free low-rank representation in an online manner for natural image segmentation
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/CII.jpg' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[A lightweight and accurate recognition framework for signs of X-ray weld images](https://arxiv.org/pdf/2110.09278.pdf)

<span style="color:red; font-weight:bold;">Moyun Liu</span>, Jingming Xie, Jing Hao, Yang Zhang, Xuzhan Chen, Youping Chen

**Computers in Industry, 2022**

- We propose a signs recognition framework based on convolutional neural networks (CNNs) for weld images. The proposed framework firstly contains a shallow classification network for correcting the pose of images, and a narrow network for final weld information recognition.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/TII2021-paper.jpg' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[A Unified Light Framework for Real-time Fault Detection of Freight Train Images](https://arxiv.org/pdf/2102.00381.pdf)

Yang Zhang, <span style="color:red; font-weight:bold;">Moyun Liu\*</span>, Yang Yang, Yanwen Guo, Huiming Zhang

**IEEE Transactions on Industrial Informatics, 2021**

- We propose a unified light framework to improve detection accuracy while supporting a real-time operation with a low resource requirement.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/TMM2021-paper.jpg' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Affinity fusion graph-based framework for natural image segmentation](https://arxiv.org/pdf/2006.13542.pdf)

Yang Zhang, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Jingwu He, Fei Pan, Yanwen Guo

**IEEE Transactions on Multimedia, 2021** \| [![](https://img.shields.io/github/stars/Yangzhangcst/AF-graph?style=social&label=Code Stars)](https://github.com/Yangzhangcst/AF-graph)

- We propose an affinity fusion graph framework to effectively connect different graphs with highly discriminating power and nonlinearity for natural image segmentation.
</div>
</div>


<!-- <div class='paper-box'><div class='paper-box-image'><img src='images/TIM-2020.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[Real-time vision-based system of fault detection for freight trains](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8911418)

Yang Zhang, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Yunian Chen, Hongjie Zhang, Yanwen Guo

**IEEE Transactions on Instrumentation and Measurement, 2020**

- We propose a real-time vision-based system of fault detection (RVBS-FD) for freight trains aims to complete routine maintenance tasks efficiently for ensuring railway transportation security.
</div>
</div> -->
<!-- 
# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üìù Other Publications 
<ul style="list-style-type: none; padding-left: 0; font-family: Arial, sans-serif; font-size: 14px; line-height: 1.4;">
  <li style="margin-bottom: 12px;">
    <a href="https://arxiv.org/pdf/2602.11007"><strong>LaSSM: Efficient Semantic-Spatial Query Decoding via Local Aggregation and State Space Models for 3D Instance Segmentation</strong></a><br>
    <em>IEEE TCSVT, 2026</em>
    &nbsp;|&nbsp; <a href="https://github.com/RayYoh/LaSSM"><img src="https://img.shields.io/github/stars/RayYoh/LaSSM?style=social&label=Code Stars" alt="Code Stars"></a><br>
    Lei Yao, Yi Wang, Yawen Cui, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Lap-Pui Chau
  </li>
  <li style="margin-bottom: 12px;">
    <a href="https://arxiv.org/pdf/2404.01065"><strong>T-Mamba: A unified framework with Long-Range Dependency in dual-domain for 2D & 3D Tooth Segmentation</strong></a><br>
    <em>IEEE TMM, 2025</em>
    &nbsp;|&nbsp; <a href="https://github.com/isbrycee/T-Mamba"><img src="https://img.shields.io/github/stars/isbrycee/T-Mamba?style=social&label=Code Stars" alt="Code Stars"></a><br>
    Jing Hao, Yonghui Zhu, Lei He, <span style="color:red; font-weight:bold;">Moyun Liu</span>, James Kit Hon Tsoi, Kuo Feng Hung
  </li>
  <li style="margin-bottom: 12px;">
    <a href="https://ieeexplore.ieee.org/document/11119324"><strong>Generalized Probabilistic Graphical Modeling for Multi-view Bipartite Graph Clustering</strong></a><br>
    <em>IEEE TPAMI, 2025</em>
    &nbsp;|&nbsp; <a href="https://github.com/liliangnudt/GProM"><img src="https://img.shields.io/github/stars/liliangnudt/GProM?style=social&label=Code Stars" alt="Code Stars"></a><br>
    Liang Li, Yuangang Pan, Yinghua Yao, Junpu Zhang, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Xinwang Liu, Kenli Li, Keqin Li
  </li>
  <li style="margin-bottom: 12px;">
    <a href="https://arxiv.org/abs/2508.02172"><strong>GaussianCross: Cross-modal Self-supervised 3D Representation Learning via Gaussian Splatting</strong></a><br>
    <em>ACM MM, 2025</em>
    &nbsp;|&nbsp; <a href="https://github.com/RayYoh/GaussianCross"><img src="https://img.shields.io/github/stars/RayYoh/GaussianCross?style=social&label=Code Stars" alt="Code Stars"></a><br>
    Lei Yao, Yi Wang, Yi Zhang, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Lap-Pui Chau
  </li>

  <li style="margin-bottom: 12px;">
    <a href="https://www.sciencedirect.com/science/article/pii/S0952197624009485"><strong>Multiple prior representation learning for self-supervised monocular depth estimation via hybrid transformer</strong></a><br>
    <em>Engineering Applications of Artificial Intelligence, 2024</em><br>
    Guodong Sun, Junjie Liu, Mingxuan Liu, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Yang Zhou
  </li>

  <li style="margin-bottom: 12px;">
    <a href="https://ieeexplore.ieee.org/document/10570157"><strong>Efficient Visual Fault Detection for Freight Train via Neural Architecture Search With Data Volume Robustness</strong></a><br>
    <em>IEEE Transactions on Industrial Informatics, 2024</em><br>
    Yang Zhang, Mingying Li, Huilin Pan, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Yang Zhang
  </li>

  <li style="margin-bottom: 12px;">
    <a href="https://arxiv.org/pdf/2407.11564"><strong>SGIFormer: Semantic-guided and Geometric-enhanced Interleaving Transformer for 3D Instance Segmentation</strong></a><br>
    <em>IEEE Transactions on Circuits and Systems for Video Technology, 2024</em>
    &nbsp;|&nbsp; <a href="https://github.com/RayYoh/SGIFormer"><img src="https://img.shields.io/github/stars/RayYoh/SGIFormer?style=social&label=Code Stars" alt="Code Stars"></a><br>
    Lei Yao, Yi Wang, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Lap-Pui Chau
  </li>

  <li style="margin-bottom: 12px;">
    <a href="https://www.sciencedirect.com/science/article/pii/S0262885623002093"><strong>BF3D: Bi-directional fusion 3D detector with semantic sampling and geometric mapping</strong></a><br>
    <em>Image and Vision Computing, 2023</em><br>
    Yijie Zhu, Jingming Xie, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Lei Yao, Youping Chen
  </li>

  <li style="margin-bottom: 12px;">
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8911418"><strong>Real-time vision-based system of fault detection for freight trains</strong></a><br>
    <em>IEEE Transactions on Instrumentation and Measurement, 2020</em><br>
    Yang Zhang, <span style="color:red; font-weight:bold;">Moyun Liu</span>, Yunian Chen, Hongjie Zhang, Yanwen Guo
  </li>
</ul>


<!-- # üë¨ Competition
<div class='paper-box'><div class='paper-box-image'><img src='images/certificate.jpg' alt="sym" width="70%"></div>
<div class='paper-box-text' markdown="1">

The 6th place in ToothFairy2 : Semi-supervised Teeth Segmentation hold on **MICCAI2024**. Many thanks to our team leader, [Jing HAO](https://isbrycee.github.io/).
</div>
</div> -->

# üë®‚Äçüéì Academic Service

 - **Reviewer**

IEEE Transactions on Pattern Analysis and Machine Intelligence

IEEE Transactions on Intelligent Transportation Systems

IEEE Transactions on Intelligent Vehicles

IEEE Transactions on Industrial Informatics

IEEE Transactions on Automation Science and Engineering

IEEE Transactions on Artificial Intelligence

IEEE Sensors Journal

Information Fusion

Pattern Recognition

Computers in Industry

Knowledge-Based Systems

Engineering Applications of Artificial Intelligence

Expert Systems With Applications 

International Conference on Learning Representations (ICLR)

ACM Multimedia (ACM MM)

- **Conference Service**

Program Committees of 2023 the 1st International Conference on AI-generated Content (AIGC2023)


<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=utH4ywUXvDZarENPjRcCDiGKVLCHBKGMoqhVBRvDpKw"></script>